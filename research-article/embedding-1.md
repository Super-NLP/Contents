---
description: 2024년 11월 4일
---

# Embedding을 평가하는 방법 (1)

<figure><img src="../.gitbook/assets/image (35).png" alt=""><figcaption><p>Embedding을 평가하는 방법</p></figcaption></figure>

RAG를 하다보면 Embedding Model을 가장 많이 접하게 된다. 다양한 모델을 활용하여 작업을 하던 도중 문득 그런 생각이 들었다. "어라, 임베딩 모델은 왜 항상 Retriever로만 성능을 평가하지? 자체 평가방식이 없나?" 오늘은 Embedding Model에 대한 평가를 어떻게 진행해야 하는지에 대해 알아보자.

Embedding은 자연어 처리(NLP)에서 텍스트 형태의 데이터를 벡터 형태의 데이터로 변환하는 기술이다. 종류가 매우 다양하며 각각의 임베딩은 다른 방식과 특징을 지닌다. 가장 널리 알려진 방식을 먼저 알아보자.

1. **Word2Vec** :&#x20;
   1. Skip-Gram과 Continous Bag of Words (CBOW)라는 2가지 모델로 구성된다. 주변단어를 이용해 대상단어를 예측하여 단어의 분산표현을 학습하며 이 방식은 단어간 의미적 관계를 캐치하여 벡터공간에 서로 가깝게 매핑된다.
2. **GloVe** :&#x20;
   1. 단어간의 통계정보를 활용하여 학습하는 방식이다. 대규모 corpus의 동시등장행렬을 기반으로 특정 단어가 다른 단어와 함께 등장하는 빈도를 활용하여 각 단어의 의미를 벡터 공간에 포함시키게 된다. 해당 과정에서 단어와 단어 사이의 의미적 관계를 반영하는 효과를 내며 Word2Vec과 달리 전체 문맥 정보를 효과적으로 학습할 수 있어 단어 간 의미적 유사성을 잘 나타낸다.
3. **Subword Embedding** :&#x20;
   1. 단어를 더 작은 단위(subword)로 나누어 임베딩하는 방식으로, 희소하거나 새롭게 등장하는 단어에 대한 처리를 효과적으로 할 수 있는 방법이다. 일반적인 단어 임베딩(Word2Vec, GloVe 등)이 단어 자체를 벡터로 표현하는 데 비해, subword 임베딩은 단어의 부분 단위(예: 접두사, 접미사, 어근 등)를 임베딩하여 합성한다. 이러한 방식은 언어의 조합을 잘 반영할 수 있어 OOV(out-of-vocabulary) 문제를 해결하고, 희귀한 단어도 잘 표현할 수 있다. 대표적으로 BPE(Byte-Pair Encoding)와 Uni-Gram Language Model이 해당하며 BERT계열 모델이 해당 방식으로 임베딩한다.

이렇듯 다양한 임베딩 방식이 존재하는데, 대다수가 성능평가를 하는데 있어 Retriever를 수행하고 있어보였다. Embedding의 본질은 단어를 벡터로 표현하는것에 있는것이지 않은가? 필자는 방금 말한 성능을 직접적으로 평가할 수는 없는지 궁금해졌고 나름 조사해보았다.

가장 먼저 알아본것은 널리 알려진 평가방식들이었다. 내용은 아래와 같다.

1. **Similarity Evaluation**
   1. 단어 벡터간 유사성을 측정하여, 유사한 의미를 가진 단어들이 벡터공간에 서로 가깝게 매핑될 것이다. 이에 대한 평가를 의미하며 주로 Cosine Similarity를 사용한다.
2. **Analogy Test**
   1. 단어 벡터간의 선형성을 평가한다. 즉, 'king - man + woman = queen'와 같은 문제를 해결할 수 있는지 없는지 확인하는 방식이다.
3. **Downstream Task Performance**
   1. 다운스트림 테스크에 해당하는 평가를 통해 성능을 확인하는 방식이다.

음... 그만 알아보자.. 무언가.. 크게 달라지는게 없는듯 하다. 이제 나에게 남은건 단 하나의 방법뿐.. "없으면 만들어보자!" 즉, Specific한 Domain에 대해 학습된 Embedding Model의 성능을 측정할 수 있는 방법을 한번 만들어보자!&#x20;

_Embedding을 평가하는 방법 (2) 에서 계속..!_
