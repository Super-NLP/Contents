---
description: Powerful Reference for Gen.AI ✨
cover: >-
  https://images.unsplash.com/photo-1532012197267-da84d127e765?crop=entropy&cs=srgb&fm=jpg&ixid=M3wxOTcwMjR8MHwxfHNlYXJjaHw4fHxsaWJyYXJ5fGVufDB8fHx8MTczMDAyMTMyNXww&ixlib=rb-4.0.3&q=85
coverY: 0
---

# 📖 Appendix

## Dataset

* **LogicKor**
  * [https://github.com/StableFluffy/LogicKor](https://github.com/StableFluffy/LogicKor)
  * [https://lk.instruct.kr/](https://lk.instruct.kr/)
* **AwesomeKorean Data**
  * [https://github.com/songys/AwesomeKorean\_Data](https://github.com/songys/AwesomeKorean\_Data)
* **KorQuad**
  * [https://github.com/korquad/korquad.github.io](https://github.com/korquad/korquad.github.io)
* **CounselGPT : 한국어 심리 상담 데이터셋**
  * [https://github.com/MrBananaHuman/CounselGPT](https://github.com/MrBananaHuman/CounselGPT)
* **Welfare-QA : 한국엉 복지제도 관련 QA 데이터셋**
  * [https://github.com/ash-hun/Welfare-QA](https://github.com/ash-hun/Welfare-QA)
* **KLUE**
  * [https://github.com/KLUE-benchmark/KLUE](https://github.com/KLUE-benchmark/KLUE)
* **Korpora**
  * [https://github.com/ko-nlp/Korpora](https://github.com/ko-nlp/Korpora)
* **국립국어원 사전**
  * [https://github.com/spellcheck-ko/korean-dict-nikl](https://github.com/spellcheck-ko/korean-dict-nikl)
* **한국어 챗봇데이터**
  * [https://github.com/songys/Chatbot\_data](https://github.com/songys/Chatbot\_data)
* **Korean HateSpeech Data**
  * [https://github.com/kocohub/korean-hate-speech](https://github.com/kocohub/korean-hate-speech)
* **Awesome Korean NLP Paper**
  * [https://github.com/changukshin/Awesome-Korean-NLP-Papers](https://github.com/changukshin/Awesome-Korean-NLP-Papers)



## Reference

* **Easy PDF Chunking open-source library : Open-Parse**
  * [https://github.com/Filimoa/open-parse](https://github.com/Filimoa/open-parse)
* **모델학습시 GPU 사용량 계산하는 사이트**
  * [https://huggingface.co/spaces/Vokturz/can-it-run-llm](https://huggingface.co/spaces/Vokturz/can-it-run-llm)
* **Open Ai : Transformer Debugger**
  * [https://github.com/openai/transformer-debugger](https://github.com/openai/transformer-debugger)
* **Langchain Visualizer**
  * [https://github.com/amosjyng/langchain-visualizer](https://github.com/amosjyng/langchain-visualizer)
* **RingAttention**
  * [https://github.com/lhao499/RingAttention](https://github.com/lhao499/RingAttention)
* **Awesome LLM Tabular**
  * [https://github.com/johnnyhwu/Awesome-LLM-Tabular](https://github.com/johnnyhwu/Awesome-LLM-Tabular)
* **Awesome LLM**
  * [https://github.com/Hannibal046/Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)
* **Awesome Korean LLM**
  * [https://github.com/NomaDamas/awesome-korean-llm](https://github.com/NomaDamas/awesome-korean-llm)
* **MiniGPT-4 (opensource)**
  * [https://github.com/Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)
* **transformer library tutorial**
  * [https://huggingface.co/docs/transformers/v4.39.1/ko/index](https://huggingface.co/docs/transformers/v4.39.1/ko/index)
  * [https://github.com/NielsRogge/Transformers-Tutorials](https://github.com/NielsRogge/Transformers-Tutorials)
* **Py2Mojo**
  * [https://github.com/msaelices/py2mojo](https://github.com/msaelices/py2mojo)
* **Awesome Korean speech recognition**
  * [https://github.com/rtzr/Awesome-Korean-Speech-Recognition](https://github.com/rtzr/Awesome-Korean-Speech-Recognition)
* **Open Korean instructions**
  * [https://github.com/HeegyuKim/open-korean-instructions](https://github.com/HeegyuKim/open-korean-instructions)
* **Practical MLOps**
  * [https://github.com/paiml/practical-mlops-book](https://github.com/paiml/practical-mlops-book)
* **Embedding (ratsgo 한국어 임베딩 도서 코드)**
  * [https://github.com/ratsgo/embedding](https://github.com/ratsgo/embedding)



* [https://wikidocs.net/book/2788](https://wikidocs.net/book/2788)
* [https://brunch.co.kr/@learning/12](https://brunch.co.kr/@learning/12)
* [https://ratsgo.github.io/nlpbook/](https://ratsgo.github.io/nlpbook/)
* [https://real-myeong.tistory.com/41](https://real-myeong.tistory.com/41)
* [https://wikidocs.net/92961](https://wikidocs.net/92961)
* [https://wikidocs.net/99893](https://wikidocs.net/99893)
* [https://devocean.sk.com/blog/techBoardDetail.do?ID=164570\&boardType=techBlog#none](https://devocean.sk.com/blog/techBoardDetail.do?ID=164570\&boardType=techBlog#none)
* [https://devocean.sk.com/blog/techBoardDetail.do?page=\&boardType=undefined\&query=\&ID=165452\&searchData=\&subIndex=#none](https://devocean.sk.com/blog/techBoardDetail.do?page=\&boardType=undefined\&query=\&ID=165452\&searchData=\&subIndex=#none)

## Fine tune

* **WhatsApp : Finetune a LLM to speak like you based on your WhatsApp Conversations**
  * [https://github.com/Ads-cmu/WhatsApp-Llama](https://github.com/Ads-cmu/WhatsApp-Llama)
* **KB-ALBERT : KB국민은행에서 제공하는 경제/금융 도메인에 특화된 한국어 ALBERT 언어모델**
  * [https://github.com/KB-AI-Research/KB-ALBERT](https://github.com/KB-AI-Research/KB-ALBERT)

## Methods

* PPO
  * [https://velog.io/@uonmf97/HUFS-RL-%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5-Reinforcement-Learning-PPO-Proximal-PolicyOptimization](https://velog.io/@uonmf97/HUFS-RL-%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5-Reinforcement-Learning-PPO-Proximal-PolicyOptimization)
* HumanFeedback
  * RLHF
    * [https://tech.scatterlab.co.kr/luda-rlhf/](https://tech.scatterlab.co.kr/luda-rlhf/)
* MoE
* RoPe Scaling
* Data Augementation
  * TransformersData Augementation
    * [https://github.com/varunkumar-dev/TransformersDataAugmentation](https://github.com/varunkumar-dev/TransformersDataAugmentation)
    *
* Domain Adaptation
  * Generative Pseudo Labeling(GPL) : Unsupervised Domain Adaptation of Dense Retrieval
    * [https://github.com/UKPLab/gpl](https://github.com/UKPLab/gpl)
* X Algorithm
  * [https://github.com/twitter/the-algorithm-ml](https://github.com/twitter/the-algorithm-ml)



## Quantizations

* PEFT
* LoRA
* QLoRA
* Knwoledge Distillation
  * [https://velog.io/@qtly\_u/%EB%AA%A8%EB%8D%B8-%EA%B2%BD%EB%9F%89%ED%99%94-%EA%B8%B0%EB%B2%95-Knowledge-Distillation](https://velog.io/@qtly\_u/%EB%AA%A8%EB%8D%B8-%EA%B2%BD%EB%9F%89%ED%99%94-%EA%B8%B0%EB%B2%95-Knowledge-Distillation)



## Alignments

* DPO
* Instruct Following
* **OpenAi Alignment handbook**
  * [https://github.com/huggingface/alignment-handbook](https://github.com/huggingface/alignment-handbook)
* **LoRA Instruct**
  * [https://github.com/leehanchung/lora-instruct](https://github.com/leehanchung/lora-instruct)



## Prompt Engineering

* **Guide book**
  * [https://github.com/dair-ai/Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
* **Basic methods**
  * zero-shot
  * one-shot
  * few-shot
* **Chain of Thought**
* **Self-Consistency**
* **Tree of Thought**
* [https://www.promptingguide.ai/kr/techniques/cot](https://www.promptingguide.ai/kr/techniques/cot)
* [https://docs.anthropic.com/claude/prompt-library](https://docs.anthropic.com/claude/prompt-library)



> **Keyword**\
> \-> Docker, Kubernates(k8s), FastAPI, MLflow, vLLM, Lakehouse, Blue/Green, LoadBalancing

### **✅ How to serve LLM in real service**

* **Prototype** or **PoC Level**
  * 서빙도 FastAPI + Uvicorn 활용해서 간단하게 수행 가능
* **Product Level**
  * 공통적으로 Service (Server) ↔ Model (Proxy Server + Docker + Kubernates가 정석으로 활용되는듯 함. PyTorch, Tensorflow, Langchain, Ollama, Azure Databricks, MLFlow, Lakehouse, etc… 여러가지 배포환경에 따라 사용하는 프레임워크는 다양하게 나뉠 것으로 보임.
  * **On-premise 환경**
    * 온프레미스 환경은 원격환경에서 서버를 운영하는 클라우드와는 대비되는 개념으로 **기업이 서버를 자체적으로 보유하고 직접 설치 및 운영하는 방식**을 의미함.
    * 데이터 보안이나 외부망 활용이 제한되는 경우, 필수적으로 LangChain 프레임워크를 활용해야할 것으로 판단됨
  * **Cloud 환경**
    * Azure 클라우드 기반으로 **Azure Databricks** 등의 다양한 기능을 활용하여 LangChain 어플리케이션을 개발할 수 있음.



### 📜 Reference

[LangChain: LLM 서비스를 어떻게 개발할 수 있을까?](https://bigwaveai.tistory.com/76)

[새로운 루다를 지탱하는 모델 서빙 아키텍처 — 1편: A/B 테스트를 위한 구조 설계](https://tech.scatterlab.co.kr/serving-architecture-1/)

[새로운 루다를 지탱하는 모델 서빙 아키텍처 — 2편: ArgoCD와 모델 서빙](https://tech.scatterlab.co.kr/serving-architecture-2/)

[HyperCLOVA 서빙 프레임워크 선정 | CLOVA Engineering Blog](https://engineering.clova.ai/posts/2022/01/hyperclova-part-1)

[NSML - 분산 학습 플랫폼의 스케줄링 요구 사항과 해결 방안 | CLOVA Engineering Blog](https://engineering.clova.ai/posts/2022/08/nsml-scheduler-part-1)

[vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention](https://blog.vllm.ai/2023/06/20/vllm.html)

[https://www.ray.io/](https://www.ray.io/)

[https://yozm.wishket.com/magazine/detail/2515/](https://yozm.wishket.com/magazine/detail/2515/)

[https://docs.wandb.ai/ko/guides](https://docs.wandb.ai/ko/guides)

[https://github.com/langgenius/dify](https://github.com/langgenius/dify)



[https://blog.doctor-cha.com/buliding-local-airflow-and-apply-vault](https://blog.doctor-cha.com/buliding-local-airflow-and-apply-vault)





* **Vector DB**
  * FAISS
  * ChromaDB
  * Redis
* **RAG**
  * LangChain
    * [https://python.langchain.com/docs/get\_started/introduction](https://python.langchain.com/docs/get\_started/introduction)
    * [https://wikidocs.net/book/14314](https://wikidocs.net/book/14314)
* **Application**
  * pyscript : [https://github.com/pyscript/pyscript](https://github.com/pyscript/pyscript)
  * Chainlit : [https://github.com/Chainlit/chainlit](https://github.com/Chainlit/chainlit)
  * Phidata : [https://github.com/phidatahq/phidata](https://github.com/phidatahq/phidata)
  * Ollama : [https://github.com/ollama/ollama](https://github.com/ollama/ollama)
* **Agent**
  * BabyAGI
  * Autonomous Agent
  * HAAS (Hierarchical Autonomous Agent Swarm)
    * [https://github.com/daveshap/OpenAI\_Agent\_Swarm](https://github.com/daveshap/OpenAI\_Agent\_Swarm)&#x20;



<mark style="color:blue;">**PS.**</mark> <mark style="background-color:blue;">(NLP & LLM & GenAI와 관련없지만 주인장 본인의 관심사 ㅎㅎ..)</mark>

* **StreamDiffusion의 realtime interactive generation의 원리**
  * [https://github.com/cumulo-autumn/StreamDiffusion](https://github.com/cumulo-autumn/StreamDiffusion)

***

### **Reference**

* Project Template
  * [https://modulabs.co.kr/blog/python-env-poetry/](https://modulabs.co.kr/blog/python-env-poetry/)
* Langchain Tutorial
  * [https://wikidocs.net/234008](https://wikidocs.net/234008)
* Deploying Langchain apps with langserve on GCP
  * [https://webcache.googleusercontent.com/search?q=cache:https://medium.com/@tahreemrasul/deploying-langchain-apps-with-langserve-on-gcp-1908476cdc49](https://webcache.googleusercontent.com/search?q=cache:https://medium.com/@tahreemrasul/deploying-langchain-apps-with-langserve-on-gcp-1908476cdc49)
* Smilegates AI : VectorDB
  * [https://smilegate.ai/2023/11/07/vector-database-%eb%b2%a1%ed%84%b0-%ec%9e%84%eb%b2%a0%eb%94%a9%ec%9d%84-%ec%a0%80%ec%9e%a5%ed%95%98%ea%b3%a0-%ea%b2%80%ec%83%89%ed%95%98%eb%8a%94-%ea%b0%80%ec%9e%a5-%ed%9a%a8%ec%9c%a8%ec%a0%81/](https://smilegate.ai/2023/11/07/vector-database-%EB%B2%A1%ED%84%B0-%EC%9E%84%EB%B2%A0%EB%94%A9%EC%9D%84-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B3%A0-%EA%B2%80%EC%83%89%ED%95%98%EB%8A%94-%EA%B0%80%EC%9E%A5-%ED%9A%A8%EC%9C%A8%EC%A0%81/)
* Weekly NLP
  * [https://jiho-ml.com/tag/weekly-nlp/](https://jiho-ml.com/tag/weekly-nlp/)
* Chris : machinecurve site
  * [https://machinecurve.com/index22.php](https://machinecurve.com/index22.php)
* Wikipedia : TEX
  * [https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:TeX\_%EB%AC%B8%EB%B2%95](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:TeX\_%EB%AC%B8%EB%B2%95)



* **vLLM : A high-throughput and memory-efficient inference and serving engine for LLMs**
  * [https://github.com/vllm-project/vllm](https://github.com/vllm-project/vllm)
* **FlashAttention : Fast and memory-efficient exact attention**
  * [https://github.com/Dao-AILab/flash-attention](https://github.com/Dao-AILab/flash-attention)
