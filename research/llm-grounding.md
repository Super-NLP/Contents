---
description: 2024년 6월 16일
---

# LLM과 Grounding

![thumnail](https://velog.velcdn.com/images/ash-hun/post/9b6a3e04-7da1-468b-ae20-aee677b058d0/image.png)

### Ⅰ. 잘못되었을지도 모르는 답변을 어떻게 막을까?

오늘 알아볼 내용은 LLM이 생성하는 답변과 그 답변을 믿을수 있는가에 대한 내용입니다. 모든 LLM은 그 자체의 답변만으로는 사용할 수 없습니다. 아무리 성능좋은 LLM도 환각현상을 동반하기 때문이죠. RAG가 각광받는 이유중 하나가 바로 이 부분이기도 합니다. 외부 Knowledge Base를 참조하면서 근거에 기반한 답변을 생성하여 신뢰성있는 답변 생성을 하는것인데요, 오늘은 가장 널리 알려진 RAG와 더불어 다양한 신뢰성있는 답변 즉, 할루시네이션을 제어하는 여러 방법론을 소개해보겠습니다.

### Ⅱ. RAG (Retrieval-Augmented Generation)

**RAG**는 Retrieval-Augmented Generation의 약자로, 검색된 내용을 참조, 증강하여 답변을 생성하는 방식입니다. RAG는 LLM의 생성 능력을 강화하기 위해 정보 검색 기술을 결합한 것으로 크게 아래와 같은 단계로 구분할 수 있습니다.

1. **Retrieval : 정보 검색**: 사용자의 질문이나 요청에 대해 관련 정보를 외부 데이터베이스나 문서에서 검색합니다.
2. **Augmented : 보강** : 검색된 내용을 증강합니다. 해당단계는 검색시에 성능향상에도 밀접하게 관련되어있어 검색과 같이 이루어지는 경우가 많습니다.
3. **Generation : 답변 생성**: 검색된 정보를 바탕으로 언어 모델이 응답을 생성합니다. 이 단계에서는 검색된 정보가 모델의 입력으로 제공되며, 모델은 이를 활용하여 더 정확하고 관련성 높은 응답을 생성합니다.

**RAG의 장점**은 모델이 직접 학습한 지식뿐만 아니라 외부 정보에 접근하여 응답을 생성할 수 있다는 점입니다. 이는 특히 특정 정보에 대한 최신 데이터나 특정 문서 기반의 정보를 필요로 하는 경우에 매우 유용하게 사용할 수 있습니다.

### Ⅲ. Grounding

**Grounding**은 언어 모델이 문맥이나 외부 지식과 같은 실제 세계의 지식과 데이터에 근거하여 자신의 응답을 형성하게 하는 과정입니다. Grounding의 주요 목적은 모델이 생성하는 응답이 특정 상황, 문맥, 또는 도메인 지식에 맞게끔 하는 것입니다. Grounding은 다양한 형태로 구현될 수 있습니다:

1. **문맥적 Grounding**: 대화의 이전 문맥이나 대화의 흐름에 맞게 응답을 생성하는 것.
2. **도메인 Grounding**: 특정 도메인의 지식이나 정보를 바탕으로 응답을 생성하는 것. 예를 들어, 의료 상담에서는 의료 지식을 기반으로 응답을 생성해야 합니다.
3. **개인화 Grounding**: 사용자의 개인 정보나 선호도를 바탕으로 응답을 생성하는 것.

Grounding은 모델이 "현실 세계"와의 연결을 강화하여 더 신뢰할 수 있고 유용한 응답을 제공하는 데 도움을 줍니다. 사실 이렇게만 보면 Grounding이 정확히 무엇인지 와닿지 않을 수 있습니다. 추가설명을 덧붙이면, Grounding LLMs는 언어 모델에 특정 데이터나 맥락을 통합하여 보다 정확하고 도메인에 특화된 응답을 제공하는 접근 방식을 의미합니다. 우리가 널리 사용하고 있는 ChatGPT와 같은 전통적인 언어 모델은 방대한 양의 일반 텍스트 데이터로 훈련되지만, 특정 지식 소스를 기반으로 정확한 답변을 생성하는 능력이 부족할 수 있습니다. 물론 ChatGPT는 특정한 도메인이나 지식영역뿐 아니라 General한 사용목적을 두고 개발된 것이기에 옳게 개발했다고 보여지나, 현업에서는 특정한 좁은 영역에서 더 전문적인 답변생성을 필요로 하는 경우가 더 많은 것이죠. Grounding LLMs는 이러한 한계를 극복하기 위해 모델이 특정 도메인이나 데이터셋과 관련된 실제 정보를 바탕으로 응답을 생성할 수 있도록 합니다.

### Ⅳ. 요약정리

그밖에도 다양한 방법론이 존재합니다. 시스템적 접근하는 관점에서 Hallucination SafeGuard를 구축한다던지 Prompting을 활용한 Chain of Verification을 수행한다던지 많은 방식이 있으니 목적에 따라 살펴보시면 좋을 것 같습니다.

그중에서도 대표적인 방식인 RAG와 Grounding에 대해 다루어보았는데요, 비교하여 요약해보겠습니다.

* **Grounding**:
  * 외부 데이터 검색 없음.
  * LLM 학습시 특정영역의 데이터만으로 학습하여 모델의 자체 생성능력으로 답변을 만들어냄.
* **RAG**:
  * 외부 데이터 검색 사용.
  * LLM 학습 시 굳이 특정한 영역의 도메인 데이터를 활용하지 않음. 검색된 정보가 모델의 입력으로 사용됩니다.

이 두 개념은 언어 모델의 성능을 향상시키기 위한 서로 다른 접근 방식을 제공하지만 그만큼 서로 다른 특징을 지니게 됩니다. Grounding은 모델이 미리 학습한 정보와 문맥을 활용하는 반면, RAG는 외부 정보를 검색하여 이를 바탕으로 응답을 생성합니다. 현업자의 관점에서는 상황에 따라 다르겠지만 가능하다면 2가지 방식 모두 활용하는것이 좋다고 보여집니다.
