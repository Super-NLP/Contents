---
description: 언어모델과 대규모언어모델을 어떻게 평가해야 하는지 알아봅시다.
coverY: 0
---

# Introduce

* **Evaluate Metric**
  * MSE&#x20;
  * RMSE&#x20;
  * MAE&#x20;
  * MAPE&#x20;
  * Confusion Matrix&#x20;
  * Accuracy&#x20;
  * Recall&#x20;
  * Precision&#x20;
  * F1-Score&#x20;
  * ROCurve
* **PPL**
* **BenchMark**
  * GLUE BenchMark&#x20;
  * KLUE BenchMark&#x20;
  * BLEU Score&#x20;
  * MMLU
    * [https://www.kaggle.com/code/debarshichanda/llm-evaluation-mmlu-style](https://www.kaggle.com/code/debarshichanda/llm-evaluation-mmlu-style)
* **Korean BenchMark**
  * HAERAE BenchMark
  * K-MMLU
  * ko-lm-evaluation-harness
    * [https://github.com/Beomi/ko-lm-evaluation-harness](https://github.com/Beomi/ko-lm-evaluation-harness)
