---
description: NLP & LLM & RAG & GenAI & Agent 에 대한 최신 논문 동향을 파악하고 리스트를 정리해보자!
cover: >-
  https://images.unsplash.com/photo-1683723483309-fd1b42875bfb?crop=entropy&cs=srgb&fm=jpg&ixid=M3wxOTcwMjR8MHwxfHNlYXJjaHwyfHxhcmNoaXZ8ZW58MHx8fHwxNzExNTI0MjkzfDA&ixlib=rb-4.0.3&q=85
coverY: 0
layout:
  cover:
    visible: true
    size: full
  title:
    visible: true
  description:
    visible: true
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: false
---

# Paper List

> **Posting을 남기는 논문도 있고, 그렇지 않은 논문도 있습니다! 연도별 Paper List에 해당하는 각 논 하단에 원본 링크가 있다면 해당 논문은 읽은 것이고, 그렇지 않다면 읽을 예정인 논문입니다 😁**

## <mark style="color:blue;">2025.</mark>

* HoarePrompt : Structural Reasoning About Program Correctness in Natural Language
* SWI : Speaking with Intent in Large Language Models
* 4bit-Quantization in Vector Embedding for RAG
* GISTEmbed : Guided In-sample Selection of Training Negatives for Text Embedding Finetuning
  * [https://arxiv.org/pdf/2402.16829](https://arxiv.org/pdf/2402.16829)
* LongSkywork : A Training Recipe for Efficiently Extending Context Length in Large Language Models
  * [https://arxiv.org/pdf/2406.00605](https://arxiv.org/pdf/2406.00605)
* Multi-Field Adaptive Retrieval
  * [https://arxiv.org/pdf/2410.20056](https://arxiv.org/pdf/2410.20056)
* BERGEN : A Benchmarking Library for Retrieval-Augemented Generation
  * [https://arxiv.org/pdf/2407.01102](https://arxiv.org/pdf/2407.01102)
* NoLIMA : Long-Context Evaluation Beyond Literal Matching
  * [https://arxiv.org/pdf/2502.05167](https://arxiv.org/pdf/2502.05167)
* RAGVAL : Automatic Dataset Creation and Evaluation for RAG System
  * [https://www.researchgate.net/publication/388465129\_RAGVAL\_Automatic\_Dataset\_Creation\_and\_Evaluation\_for\_RAG\_Systems](https://www.researchgate.net/publication/388465129_RAGVAL_Automatic_Dataset_Creation_and_Evaluation_for_RAG_Systems)
* Qwen2.5 Technical Report
  * [https://arxiv.org/pdf/2412.15115](https://arxiv.org/pdf/2412.15115)
* Balancing Content Size in RAG-Text2SQL System
  * [https://arxiv.org/pdf/2502.15723v1](https://arxiv.org/pdf/2502.15723v1)
* Semantic Captioning : Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning in SQL2Text
* SPSQL : Step-by-step Parsing Based Framework for Text-to-SQL Generation
* PET-SQL : A Prompt-Enhanced Two-round Refinement of Text-to-SQL with Cross-consistency
* Data Ambiguity Strikes Back: How Documentation Improves GPT's Text-to-SQL
  * [https://arxiv.org/pdf/2310.18742](https://arxiv.org/pdf/2310.18742)
* Do We Need Domain-Specific Embedding Models? An Empirical Investigation
* Enhancig Text-to-SQL Translation for Financial System Design
  * [https://arxiv.org/pdf/2312.14725](https://arxiv.org/pdf/2312.14725)
* [Text2SQL is Not Enough : Unifying AI and Database with TAG](2024-text2sql-is-not-enough-unifying-ai-and-database-with-tag.md)
  * [https://arxiv.org/pdf/2408.14717](https://arxiv.org/pdf/2408.14717)
* [Don't Do RAG : When Cache-Augmented Generation is All you Need for Knowledge Tasks](2024-dont-do-rag-when-cache-augmented-generation-is-all-you-need-for-knowledge-tasks.md)
  * [https://arxiv.org/pdf/2412.15605](https://arxiv.org/pdf/2412.15605)
* BM25S : Ordered of magnitude fasteer lexical search via eagger sparse scoring
  * [https://arxiv.org/pdf/2407.03618](https://arxiv.org/pdf/2407.03618)
* MEDEC : A Benchmark for Medical Error Detection and Correction in Clinical notes
  * [https://arxiv.org/pdf/2412.19260](https://arxiv.org/pdf/2412.19260)
* [Reciprocal Rank Fusion outperforms Condorcet and individual Rank Learning Methods](2009-reciprocal-rank-fusion-outperforms-condorcet-and-individual-rank-learning-methods.md)
  * [https://dl.acm.org/doi/10.1145/1571941.1572114](https://dl.acm.org/doi/10.1145/1571941.1572114)

## <mark style="color:orange;">\~ 2024.</mark>

* [Retrieval Augmented Generation (RAG) and Beyond](2024-retrieval-augmented-generation-rag-and-beyond.md)
  * [https://arxiv.org/pdf/2409.14924v1](https://arxiv.org/pdf/2409.14924v1)
* [ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT](2020-colbert-efficient-and-effective-passage-search-via-contextualized-late-interaction-over-bert.md)
  * [https://arxiv.org/pdf/2004.12832](https://arxiv.org/pdf/2004.12832)
* [Take a Step Back : Evoking Reasoning via Abstraction in Large Language Models](2024-take-a-step-back-evoking-reasoning-via-abstraction-in-large-language-models.md)
  * [https://arxiv.org/pdf/2310.06117](https://arxiv.org/pdf/2310.06117)
* RAFT : Adapting Language Model to Domain Specific RAG
  * [https://arxiv.org/pdf/2403.10131](https://arxiv.org/pdf/2403.10131)
* [Interleaving Retrieval with Chain-of-Thought for Knowledge-Intensive Multi-Step Questions](2023-interleaving-retrieval-with-chain-of-thought-for-knowledge-intensive-multi-step-questions.md)
  * [https://arxiv.org/pdf/2212.10509](https://arxiv.org/pdf/2212.10509)
* [RAG Survey : A Survey on Retrieval-Augmented Text Generation for Large Language Models](2024-rag-survey-a-survey-on-retrieval-augmented-text-generation-for-large-language-models.md)
  * [https://arxiv.org/pdf/2404.10981](https://arxiv.org/pdf/2404.10981)
* [CoVe : Chain of Verification Reduces Hallucination in Large Language Models](2023-cove-chain-of-verification-reduces-hallucination-in-large-language-models.md)
  * [https://arxiv.org/pdf/2309.11495](https://arxiv.org/pdf/2309.11495)
* [Attention is all you need](2017-attention-is-all-you-need.md)
  * [https://arxiv.org/pdf/1706.03762](https://arxiv.org/pdf/1706.03762)
