---
description: 2025.01.26
---

# \[2024] Text2SQL is Not Enough : Unifying AI and Database with TAG

<figure><img src="../../.gitbook/assets/text2sql.png" alt="" width="563"><figcaption><p>Text2SQL is Not Enough : Unifying AI and Databases with TAG</p></figcaption></figure>

> **Paper Link** : [https://arxiv.org/pdf/2408.14717](https://arxiv.org/pdf/2408.14717)

```
※ 본 포스팅은 논문의 가장 중요한 내용에 대한 리뷰를 정리하여 올리기 때문에 다소 축약되거나 의역된 내용이 많습니
```

## ABSTRACT

데이터베이스를 통해 자연어 질문에 응답하는 AI 시스템은 엄청난 가치를 창출할 잠재력을 가지고 있습니다. 이러한 시스템은 사용자가 언어 모델(LMs)의 강력한 추론 및 지식 능력을 데이터 관리 시스템의 확장 가능한 계산 능력과 결합하여 활용할 수 있도록 합니다. 이 결합된 능력은 <mark style="color:orange;">**사용자가 맞춤형 데이터 소스에 대해 자유로운 자연어 질문을 할 수 있도록 지원**</mark>합니다. 그러나 기존의 방법과 벤치마크는 이 환경을 충분히 탐구하지 못하고 있습니다. Text2SQL 방법은 관계 대수(Relational Algebra)로 표현할 수 있는 자연어 질문에만 초점을 맞추고 있으며, 이는 실제 사용자가 묻고자 하는 질문의 작은 부분만을 나타냅니다. 마찬가지로, Retrieval-Augmented Generation (RAG)은 데이터베이스 내 하나 또는 소수의 데이터 레코드에서 포인트 조회로 답변할 수 있는 제한된 범위의 질의에만 초점을 맞추고 있습니다. 우리는 데이터베이스를 대상으로 자연어 질문에 답변하기 위한 통합적이고 범용적인 패러다임인 Table-Augmented Generation(TAG)을 제안합니다. TAG 모델은 언어 모델(LM)과 데이터베이스 간의 다양한 상호작용을 표현하며, 이전에 탐구되지 않았던 영역을 다루어 LMs의 세계 지식과 추론 능력을 데이터에 활용할 수 있는 흥미로운 연구 기회를 제공합니다. 우리는 TAG 문제를 연구하기 위한 벤치마크를 체계적으로 개발했으며, 표준 방법으로는 20% 미만의 질의만 올바르게 답변할 수 있음을 발견하여 이 분야에서 추가 연구의 필요성을 확인했습니다. 벤치마크에 대한 코드는 [https://github.com/TAG-Research/TAG-Bench](https://github.com/TAG-Research/TAG-Bench)에서 공개됩니다.

## 1. INTRODUCTION

언어 모델은 사용자가 데이터에 대해 자연어 질문을 할 수 있게 함으로써 데이터 관리의 혁신을 약속하며, 이로 인해 Text2SQL 및 Retrieval-Augmented Generation (RAG) 방법에 대한 많은 연구가 이루어졌습니다. 그러나 우리의 경험(내부 작업 및 Databricks의 고객을 포함한)으로는, 사용자들의 질문이 종종 이러한 패러다임의 한계를 넘어서는 경우가 많습니다. 이는 데이터베이스 시스템의 논리적 추론 능력과 현대 언어 모델(LMs)의 자연어 추론 능력을 결합하는 시스템에 대한 새로운 연구 투자가 필요함을 시사합니다. 특히, 실제 비즈니스 사용자의 질문은 종종 도메인 지식, 세계 지식, 정확한 계산 및 의미적 추론의 정교한 조합을 요구한다는 것을 알게 되었습니다. 데이터베이스 시스템은 최신 데이터를 저장하여 도메인 지식의 출처를 제공하고, 대규모로 정확한 계산을 수행할 수 있기 때문에 (LMs가 잘하지 못하는 부분) 중요한 역할을 합니다. LMs는 데이터베이스의 기존 기능을 두 가지 주요 방식으로 확장할 수 있습니다.&#x20;

첫째, LMs는 텍스트 데이터에 대한 의미적 추론 능력을 가지고 있으며, 이는 많은 자연어 사용자 질문의 핵심 요소입니다. 예를 들어, Databricks 고객 설문조사에서는 사용자가 "제품 X에 대한 고객 리뷰 중 어떤 것이 긍정적인가?" 또는 "왜 이 기간 동안 내 매출이 떨어졌을까?"와 같은 질문을 하고 싶어 한다고 밝혔습니다. 이러한 질문은 감정 분석이나 트렌드 요약과 같은 복잡한 추론 기반 작업을 포함합니다. LMs는 전통적인 데이터베이스 시스템의 정확한 계산이나 관계형 연산으로 모델링할 수 없는 이러한 작업에 적합합니다.

둘째, LM은 모델 훈련 중에 학습한 지식과 모델의 가중치에 암묵적으로 저장된 지식을 사용하여 사용자의 데이터를 데이터베이스의 테이블 스키마에 명시적으로 캡처되지 않은 세계 지식으로 강력하게 보강할 수 있습니다. 예를 들어, Databricks의 내부 AI 사용자는 "소매(retail) 분야의 QoQ 트렌드는 무엇인가?"라는 질문을 계정 이름, 제품 및 수익에 대한 속성을 포함하는 테이블을 보고 묻었습니다. 이 질문에 답하기 위해 시스템은 비즈니스가 QoQ를 어떻게 정의하는지(예: 마지막 분기에서 현재 분기까지의 분기별 트렌드 또는 작년 이 분기에서 올해 이 분기까지의 트렌드)와 어떤 회사들이 소매 분야에 속하는지를 이해해야 합니다. 이 작업은 사전 훈련되거나 세부 조정된 LM이 가진 지식을 활용하기에 적합합니다.

데이터베이스와 LMs를 효율적으로 결합하여 자연어 질의에 응답하는 시스템은 그 전반적인 범위에서 사용자들이 데이터를 이해하는 방식을 혁신할 잠재력을 가지고 있습니다. 불행히도, 현재 이러한 질문들은 Text2SQL이나 RAG와 같은 일반적인 방법으로는 답할 수 없습니다. Text2SQL 방법은 직접적인 관계형 대응이 있는 자연어 질의의 일부에는 적합하지만, 의미적 추론이나 세계 지식이 필요한 광범위한 사용자 질의를 처리할 수 없습니다. 예를 들어, 이전에 제시된 "어떤 고객 리뷰가 긍정적인가?"라는 질문은 각 리뷰를 긍정적 또는 부정적으로 분류하기 위해 리뷰에 대한 논리적 행 단위 LM 추론이 필요할 수 있습니다. 마찬가지로, "왜 매출이 떨어졌는가?"라는 질문은 여러 테이블 항목에 걸쳐 정보를 집계해야 하는 추론 질문을 포함합니다.

반면, RAG 모델은 몇 개의 데이터 레코드에 대한 단순한 관련성 기반 포인트 조회와 그 뒤를 따르는 한 번의 LM 호출로 제한됩니다. 이 모델은 포인트 조회로 답할 수 있는 질의의 하위 집합만 처리할 수 있으며, 많은 데이터베이스 시스템의 풍부한 질의 실행 능력을 활용하지 못합니다. 이로 인해 계산 작업(예: 카운팅, 수학 및 필터링)은 오류가 발생하기 쉬운 LM을 한 번 호출하는 것으로 처리됩니다. 계산 작업에서 오류가 발생하기 쉽고 비효율적일 뿐만 아니라, LM은 긴 맥락의 프롬프트에서 성능이 떨어지는 것으로 나타났으며, 이는 RAG의 생성 단계에서 데이터를 대규모로 추론하는 능력을 제한합니다.

우리는 대신 데이터베이스에 대한 자연어 질문에 답하는 시스템을 위한 통합된 패러다임으로 테이블 보강 생성(table-augmented generation, TAG)을 제안합니다. 구체적으로, TAG는 Figure 1에 표시된 세 가지 주요 단계를 정의합니다. 첫째, 질의 합성 단계인 **syn**은 사용자의 임의의 자연어 요청 $$\text{R}$$을 실행 가능한 데이터베이스 질의 $$\mathcal{Q}$$로 변환합니다. 그다음, 질의 실행 단계인 **exec**은 데이터베이스 시스템에서 $$\mathcal{Q}$$를 실행하여 관련 데이터를 효율적으로 계산한 $$\text{T}$$를 얻습니다. 마지막으로, 답변 생성 단계인 **gen**은 $$\text{R}$$과 $$\text{T}$$를 활용하여 LM이 데이터를 기반으로 반복적이거나 재귀적인 방식으로 조정되어 최종 자연어 답변 $$\text{A}$$를 생성합니다. TAG 모델은 간단하지만 강력합니다. 다음 세 가지 방정식으로 정의되며, LMs와 데이터베이스 간의 이전에 충분히 연구되지 않았던 다양한 상호작용을 포착합니다.

* Query Synthesis : syn($$\text{R}$$) $$\rightarrow$$→ $$\mathcal{Q}$$   ...........  (1)
* Query Execution : exec($$\mathcal{Q}$$) → $$\text{T}$$ ........... (2)
* Answer Generation : gen($$\text{R}, \text{T}$$) → $$\text{A}$$ ........... (3)

특히, TAG 모델은 이전의 방법들인 Text2SQL과 RAG를 통합합니다. 이 두 방법은 TAG의 특수한 경우에 해당하며, 제한된 사용자 질문의 하위 집합만 처리합니다.

여러 이전 연구들이 TAG의 특수한 경우를 다루었지만, 우리는 LM 추론 및 지식 능력을 요구하는 현실적인 질의를 폭넓게 포함한 첫 번째 엔드 투 엔드(TAG) 벤치마크를 제공합니다. 우리는 이러한 유형의 질문이 제시하는 중요한 연구적 도전과 효율적인 TAG 구현의 가능성을 보여줍니다. 우리의 평가에서는 기본적인 Text2SQL과 RAG 벤치마크를 비롯하여, LM 생성을 결합한 Text2SQL과 LM 기반 재순위화를 활용한 검색 방법을 포함한 두 가지 더 강력한 벤치마크를 분석합니다. 다양한 질의 유형에서 각 벤치마크 방법이 일관되게 높은 정확도를 달성하지 못하고, 정확한 일치율이 20%를 넘지 않음을 발견했습니다. 반면, 우리는 최신 LOTUS 런타임 위에 수동으로 작성한 TAG 파이프라인을 구현하여 벤치마크에 비해 최대 20-65% 더 높은 정확도를 달성했습니다. 이 성능 격차는 효율적인 TAG 시스템 구축의 가능성을 보여줍니다.

## 2. THE TAG MODEL

이제 우리는 TAG 모델에 대해 설명합니다. TAG 모델은 자연어 요청 𝑅을 받아 데이터 소스를 기반으로 자연어 답변 𝐴를 반환합니다. TAG 시스템이 구현하는 세 가지 주요 단계를 설명합니다: 질의 합성, 질의 실행, 그리고 답변 생성입니다. 우리는 TAG를 이러한 단계를 한 번 수행하는 방식으로 정의하지만, TAG를 다중 홉(multi-hop) 방식으로 확장할 수도 있습니다.

### 2.1 Query Synthesis

syn 함수는 자연어 요청 𝑅을 받아 데이터베이스 시스템에서 실행할 질의 𝑄를 생성합니다. 사용자 요청이 주어지면, 이 단계는 (a) 요청에 답하기 위해 어떤 데이터가 관련이 있는지 추론하는 작업(예: 테이블 스키마를 사용)과 (b) 사용자 요청을 데이터베이스 시스템에서 실행할 수 있는 질의로 변환하기 위해 의미론적 파싱을 수행하는 작업을 담당합니다. 이 질의는 어떤 질의 언어로든 될 수 있지만, 우리 예시에서는 SQL을 사용합니다. Figure 1은 "가장 높은 수익을 올린 로맨스 영화 중 '고전'으로 간주되는 영화의 리뷰를 요약하라"는 사용자 질의를 위한 TAG 구현 예시를 보여줍니다. 여기서 데이터 소스는 각 영화의 제목, 수익, 장르, 그리고 관련된 리뷰에 대한 정보를 포함하고 있습니다. 이 단계에서 시스템은 LM의 의미적 추론 능력을 활용하여 영화 제목, 리뷰, 수익, 장르 속성을 사용하는 SQL 질의를 생성합니다. 이 예시에서는 데이터베이스 API가 SQL 질의 내에서 LM UDF를 실행할 수 있으므로, 이 단계는 쿼리 내에서 고전 영화를 식별하기 위해 각 행에 대해 LM을 호출하는 작업도 포함합니다.

### 2.2 Query Execution

질의 실행 단계에서 exec 함수는 데이터베이스 시스템에서 질의 𝑄를 실행하여 테이블 𝑇를 얻습니다. 이 단계는 데이터베이스 질의 엔진을 활용하여 방대한 양의 저장된 데이터에 대해 효율적으로 질의를 실행합니다.

<figure><img src="../../.gitbook/assets/image (60).png" alt="" width="563"><figcaption><p><strong>Figure 1</strong> : 영화에 관한 테이블에서 사용자의 자연어 질문에 답하기 위한 TAG 구현 예시입니다. <br>TAG 파이프라인은 세 가지 단계로 진행됩니다: 질의 합성, 질의 실행, 그리고 답변 생성.</p></figcaption></figure>

데이터베이스 API는 다양한 시스템에서 제공될 수 있으며, 우리는 이를 3장에서 다룹니다. 일부 API는 LM 기반 연산자를 허용할 수 있으며, 이를 통해 데이터베이스 엔진이 exec 내에서 LM의 세계 지식과 추론 능력을 활용할 수 있습니다.

**Figure 1**에서 보여주는 예시에서는 데이터베이스 질의가 SQL로 작성된 선택 및 순위 질의이며, 관련된 행을 포함하는 테이블을 반환합니다. 이 질의는 LM을 사용하여 영화 제목에 따라 어떤 영화가 고전 영화인지를 평가하고, 장르 필터를 사용하여 로맨스 영화를 찾습니다. 또한, 수익을 기준으로 결과를 순위 매겨 가장 높은 수익을 올린 영화를 찾습니다. 그림에서 보듯이, 결과 테이블에는 영화 "타이타닉"에 대한 리뷰가 포함되어 있습니다.

### 2.3 Answer Generation







## 3. TAG DESIGN SPACE







## 4. EVALUATION







## 5. RELATED WORK







## 6. CONCLUSION













