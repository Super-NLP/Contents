# Table of contents

* [Contents](README.md)

## ü•ë Resume / CV

* [Reseume / CV](resume-cv/reseume-cv.md)

## üìÑ Paper Review

* [Paper List](paper-review/paper-list/README.md)
  * [\[2017\] Attention is all you need](paper-review/paper-list/2017-attention-is-all-you-need.md)
  * [\[2023\] CoVe : Chain of Verification Reduces Hallucination in Large Language Models](paper-review/paper-list/2023-cove-chain-of-verification-reduces-hallucination-in-large-language-models.md)
  * [\[2024\] RAG Survey : A Survey on Retrieval-Augmented Text Generation for Large Language Models](paper-review/paper-list/2024-rag-survey-a-survey-on-retrieval-augmented-text-generation-for-large-language-models.md)
  * [\[2023\] Interleaving Retrieval with Chain-of-Thought for Knowledge-Intensive Multi-Step Questions](paper-review/paper-list/2023-interleaving-retrieval-with-chain-of-thought-for-knowledge-intensive-multi-step-questions.md)
  * [\[2024\] Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models](paper-review/paper-list/2024-take-a-step-back-evoking-reasoning-via-abstraction-in-large-language-models.md)

## üóÇÔ∏è Research Article

* [Reference List](research-article/reference-list/README.md)
  * [Dataset](research-article/reference-list/dataset.md)
  * [LLM](research-article/reference-list/llm.md)
  * [Prompt Engineering](research-article/reference-list/prompt-engineering.md)
  * [LLMops](research-article/reference-list/llmops.md)
  * [RAG & Agent](research-article/reference-list/rag-and-agent.md)
  * [Etc](research-article/reference-list/etc.md)
* [Compounded AI System : The Shift from Models to Compound AI Systems](research-article/compounded-ai-system-the-shift-from-models-to-compound-ai-systems.md)
* [LLMÍ≥º Grounding](research-article/llm-grounding.md)
* [Essence of RAG](research-article/essence-of-rag.md)
* [How to reduce HALLUCINATIONS](research-article/how-to-reduce-hallucinations.md)
* [Golden Gate Claude Review](research-article/golden-gate-claude-review.md)
* [Editorial Thinking](research-article/editorial-thinking.md)
* [ÌïúÍµ≠Ïñ¥ Tokenizing ÎπÑÍµê Î∂ÑÏÑù](research-article/tokenizing.md)
