---
layout:
  title:
    visible: true
  description:
    visible: false
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: true
---

# 01-1 LLM 지도

## 1.1 딥러닝과 언어 모델링

* LLM은 사람의 언어를 컴퓨터가 이해하고 생성할 수 있도록 연구하는 자연어 처리(Natural Language Processing) 분야 중, 자연어 생성(Natural Language Generation)에 속함.
* LLM은 다음에 올 단어가 무엇일지 예측하면서 문장을 하나씩 만들어가는 방식으로 텍스트를 생성하며 이러한 모델을 언어 모델(Language Model)이라고 함.
* 2024년까지 모든 언어 생성 모델은 딥러닝 기반의 모델이며, 과거의 히스토리를 따라가면 13년 Google의 Word2Vec, 17년 Transformer, 18년 GPT-1 모델이 가장 큰 임팩트를 가져왔다.

### 1.1.1 데이터의 특징을 스스로 추출하는 딥러닝

* 딥러닝과 머신러닝의 가장 큰 차이를 보이는 것은 '데이터의 특징을 누가 뽑는가?'이다.
* 기존의 머신러닝은 데이터의 특징을 연구자 또는 개발자가 찾고 모델에 입력으로 넣는다.
* 딥러닝은 모델이 스스로 데이터의 특징을 찾고 분류하는 과정을 학습한다.

### 1.1.2 임베딩 : 딥러닝 모델이 데이터를 표현하는 방식

* 임베딩이란 데이터를 그 의미를 담아 여러 개의 숫자의 집합으로 표현하는 것을 말한다.
* 검색 및 추천, 클러스터링 및 분류, 이상치 탐지등의 작업에 활용될 수 있다.
* 단어를 임베딩으로 변환한 것을 일컬어 단어 임베딩(Word Embedding)이라고 한다.

### 1.1.3 언어 모델링 : 딥러닝 모델의 언어 학습법

* 대량의 데이터에서 언어의 특성을 학습하는 사전 학습(Pre-Training)의 방법으로 언어 모델링이 사용된다.
* 전이 학습 (Transfer Learning)은 하나의 문제를 해결하는 과정에서 얻은 지식과 정보를 다른 문제를 풀 때 사용하는 방식을 말한다.
* 미세 조정 (Fine Tuning)은 특정한 문제를 해결하기 위한 데이터로 추가학습하는 방식을 말한다.
* Pre-training model을 fine tuning하여 풀고자하는 문제를 다운스트림 과제(Downstream Task)라고 한다.

## 1.2 언어 모델이 챗GPT가 되기까지

### 1.2.1 RNN에서 트랜스포머 아키텍처로

* 작은 단위의 데이터가 연결되고 그 길이가 다양한 데이터의 형태를 '시퀀스(sequence)'라고 한다.
* 시퀀스 데이터에 텍스트, 오디오, 시계열과 같은 데이터가 포함된다.
* RNN의 특징은 hidden state에 지금까지 입력된 텍스트의 맥락을 압축한다는 점이다.
* 2017년에 등장한 트랜스포머 아키텍쳐는 순차적인 처리방식을 버리고 맥락을 모두 참조하는 어텐션(attention) 연산을 사용한다.
* 맥락을 모두 참고하여 다음 단어를 예측하기 때문에 성능을 높일 수 있지만 입력 텍스트가 길어지면 맥락 데이터를 모두 연산하고 저장해야해서 메모리 사용량이 증가한다는 점과 매번 다음 단어를 예측할 때마다 맥락 데이터를 모두 확인해야하기 때문에 예측에 걸리는 시간이 증가한다는 단점을 가진다. 즉, 성능이 높아지는 대신 무겁고 비효율적인 연산을 사용하게 된 것.

### 1.2.2 GPT 시리즈로 보는 모델 크기와 성능의 관계

* OpenAI는 18년 1억 1700만개 파라미터의 GPT-1을 공개했다.
* OpenAI는 19년 15억개의 파라미터를 가진 GPT-2를 공개했다.
* OpenAI는 20년 1750억개의 파라미터를 사용한 GPT-3를 공개했다.
* GPT-3때는 사람의 언어 생성능력과 유사하다는 평가를 받았으며 모델 구조에 큰 변경없이 모델과 학습 데이터셋의 크기만 키웠다.&#x20;
* 언어모델의 학습 과정을 학습 데이터를 압축하는 과정으로 해석할 수 있는데, 여기서의 압축은 공통되고 중요한 패턴만을 남기는 손실압축을 의미한다. 예를들면 meta의 Llama2 모델을 보면 10TB의 텍스트로 학습해 최종적으로 140GB 크기의 모델이 된다.
* 즉, 모델의 크기가 커치면 학습 데이터가 갖고 있는 언어 생성 패턴을 더 많이 학습할 수 있기 때문에 성능이 높아진다고 할 수 있다.

### 1.2.3 챗GPT의 등장

* GPT-3를 챗GPT로 바꾼 것은 지도 미세 조정(SFT, Supervised Fine Tuning)과 RLHF(Reinforcement Learning from Human Feedback) 덕분이다.
* LLM이 생성하는 답변을 사용자의 요청 의도에 맞추는 것을 정렬(alignment)라고 한다.
* SFT는 alignment를 위한 가장 핵심적인 학습 과정으로 지시 데이터(instruction dataset)을 추가 학습하는 것을 뜻한다.
* 챗GPT의 경우 사용자가 선호한 답변을 데이터셋화하여 선호 데이터셋(preference dataset)을 만들었고 이를 바탕으로 LLM의 답변을 평가하는 리워드 모델(Reward Model)을 만들었다. 이때 강화학습을 사용하기 때문에 이 기술을 RLHF라고 한다.

## 1.3 LLM 애플리케이션의 시대가 열리다

### 1.3.1 지식 사용법을 획기적으로 바꾼 LLM

* LLM의 경우 언어 이해와 언어 생성능력이 모두 뛰어나 다양한 방면에서 활용될 수 있다.

### 1.3.2 sLLM : 더 작고 효율적인 모델 만들기

* 상업적인 API를 이용하는 방법
* 오픈소스 LLM을 활용해 직접 LLM API를 생성하는 방법

### 1.3.3 더 효율적인 학습과 추론을 위한 기술

* LLM의 기반이 되는 트랜스포머 아키텍처 연산은 많은 리소스가 필요하기 때문에 학습과 추론에 필요한 연산량은 크게 증가했다.&#x20;
* 더 작은 자원으로 LLM을 활용할 수 있도록 돕는 연구가 활발한데, 대표적으로 양자화(Quantization), LoRA(Low Rank Adaptation)방식이 존재한다.

### 1.3.4 LLM의 환각 현상을 대처하는 검색증강생성(RAG) 기술

* LLM의 큰 문제는 바로 '환각현상(Hallucination)'으로 이는 LLM이 잘못된 정보나 실제로 존재하지 않는 정보를 만들어 내는 현상을 말한다.
* 이러한 Hallucination을 줄이기 위해 RAG기술을 사용한다.

## 4. LLM의 미래: 인식과 행동의 확장

* LLM이 더 다양한 데이터(이미지, 오디오, 비디오 등)를 처리할 수 있도록 발전시킨 멀티모달(Multi-Modal)LLM
* LLM이 멀티모달로 변화함에 따라 사용하는 멀티모달 RAG
* LLM이 단순히 텍스트를 생성하는 기능 외에 스스로 판단하고 행동하는 Agent
